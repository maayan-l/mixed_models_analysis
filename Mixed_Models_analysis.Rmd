---
title: "Models A - Final Assignment"
author: "Ma'ayan Levinson"
date: "March 2018"
output:
  pdf_document: default
  html_document:
    df_print: paged
header-includes: \usepackage{xcolor}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
library("faraway")
library("Matrix")
library("lme4")
library("knitr")
library("ggplot2")
library("kableExtra")
library("gridExtra")
options(knitr.table.format = "latex")
data(lawn)
```

## Mixed Model  

I  first set up the problem as a mixed model.

```{r Fitting MM}
X <- as.data.frame(matrix(1, 24,3))
colnames(X) <- c("intercept","manufacturer","speed")

X$manufacturer <- ifelse((lawn$manufact=="B") ,-1,1) # A=1, B=-1
X$speed <- ifelse((lawn$speed=="L") ,-1,1) # H=1, L=-1
X <- as.matrix(X)

Z <- matrix(0, 24, 6)
colnames(Z) <- c(1:6)
Z[,1] <- ifelse(lawn$machine=="m1", 1, 0)
Z[,2] <- ifelse(lawn$machine=="m2", 1, 0)
Z[,3] <- ifelse(lawn$machine=="m3", 1, 0)
Z[,4] <- ifelse(lawn$machine=="m4", 1, 0)
Z[,5] <- ifelse(lawn$machine=="m5", 1, 0)
Z[,6] <- ifelse(lawn$machine=="m6", 1, 0)
```


The model included the munufacturers and the speed levels as fixed effects. The fixed effect design matrix \textcolor{purple}{X} included one column for the intercept, a column for the manufacturer and a column for the fixed effect of the speed.  
Manufacturer **A** was signified as +1 in the manufacturer column and manufacturer **B** was signified as -1. Speed **H** (high) was signified as +1 in the speed column and **L** (low) was -1.  
The model included a random effects for each of the 6 lawnmowers (3 machines `*` 2 manufactureres). the design matrix \textcolor{purple}{Z} included one column for each machine with 4 measurements each (2 speeds `*` twice).
   
```{r display }
display_X <- cbind(as.numeric(row.names(lawn)),X,Z)
display_X <- display_X[order(display_X[,5], display_X[,6], display_X[,7], decreasing=T),]
kable(display_X, longtable = F, booktabs=T) %>%
  add_header_above(c("obs","X -- Fixed"=3,"Z -- Random"=6)) %>%
  row_spec(5:8, background = "#DCDCDC") %>%
  row_spec(13:16, background = "#DCDCDC") %>%
  row_spec(21:24, background = "#DCDCDC")
```



Using the random effects estimators calculated with *lmer*, I calculated the fixed effect to be:
  
```{r ME}
# Using lmer to calculate the random effects
lawn_design <- lawn
lawn_design$manufact <- ifelse((lawn$manufact=="B") ,-1,1)
lawn_design$speed <- ifelse((lawn$speed=="L") ,-1,1)
ME_results <- lmer(time~manufact + speed + (1 | machine), data=lawn_design)

#saving the values of the random effects
sigma_random <- as.data.frame(VarCorr(ME_results))$vcov[1]
sigma_residual <- as.data.frame(VarCorr(ME_results))$vcov[2]


cov_Y <- (sigma_random * Z %*% t(Z)) + (sigma_residual * diag(24))
beta_ME <- (solve(t(X) %*% solve(cov_Y) %*% X)) %*% (t(X) %*% solve(cov_Y) %*% lawn$time)
cov_betaME <- solve(t(X) %*% solve(cov_Y) %*% X)
z_value <- qnorm(0.975)
CI_betaME <- cbind(beta_ME - z_value*sqrt(diag(cov_betaME)), beta_ME + z_value*sqrt(diag(cov_betaME)))
rownames(CI_betaME) <- c("intercept", "manufacturer", "speed")
colnames(CI_betaME) <- c("lower", "upper")
kable(round(cbind(CI_betaME[,1],beta_ME, CI_betaME[,2]), 3), booktabs=T, col.names = c("lower bound", "beta","upper bound")) %>%
  column_spec(3,bold=T)
```
with confidence interval of 95%.

## Ordinary Least Squares  

I calculated estimations for the effects of manufacturers and speed on time. In this model I disregarded the clustering of the machine as a random variable and rather added it to the fixed effect.
The Confidence Interval for the estimator in this model was calculated to be:

```{r OLS}

machines_fixed <- matrix(0, 24, 4)
colnames(machines_fixed) <- c("m2-m1", "m3-m1", "m5-m4", "m6-m4")
machines_fixed[,1] <- ifelse(lawn$machine=="m2",1,ifelse(lawn$machine=="m1",-1,0))
machines_fixed[,2] <- ifelse(lawn$machine=="m3",1,ifelse(lawn$machine=="m1",-1,0))
machines_fixed[,3] <- ifelse(lawn$machine=="m5",1,ifelse(lawn$machine=="m4",-1,0))
machines_fixed[,4] <- ifelse(lawn$machine=="m6",1,ifelse(lawn$machine=="m4",-1,0))


X_ols <- cbind(X, machines_fixed)
beta_ols <- (solve(t(X_ols) %*% X_ols)) %*% (t(X_ols) %*% lawn$time)
cov_betaOLS <- solve(t(X_ols) %*% X_ols)
CI_betaOLS <- cbind(beta_ols - z_value*sqrt(diag((cov_betaOLS))),
                    beta_ols + z_value*sqrt(diag((cov_betaOLS))))
rownames(CI_betaOLS) <- c("intercept", "manufacturer", "speed","m2-m1", "m3-m1", "m5-m4", "m6-m4")
colnames(CI_betaOLS) <- c("lower", "upper")
kable(round(cbind(CI_betaOLS[,1],beta_ols, CI_betaOLS[,2]), 3), format="latex", booktabs=T, col.names = c("lower bound", "beta","upper bound")) %>%
  column_spec(3,bold=T)
```
## Bootstrap sampling  
  
follwing is a function I wrote to sample the dependent variable $Y = time$ using the ME model and the parameters designed above. 
  
### input:  
\textcolor{purple}{X} design matrix of the fixed effects  
\textcolor{purple}{Z} design matrix of the random effects  
\textcolor{blue}{$\beta$} the coeficients of the fixed effects  
\textcolor{brown}{${{\sigma}^2}_\gamma,\ {{\sigma}^2}_\epsilon$} variance of the random effect and of the residuals.  
  
### output:  
\textcolor{olive}{$Y^*$}, a sample of results matching the number of observations in \textcolor{purple}{X}, \textcolor{purple}{Z}.

```{r sampling function, echo = T}
me_gen <- function(X,Z,beta_ME,sigma_random, sigma_residual){
  
  gamma_ME  <- rnorm(6, mean = 0, sd = sqrt(sigma_random))
  epsilon   <- rnorm(24, mean = 0 , sd = sqrt(sigma_residual))
  Y_star    <- X %*% beta_ME + Z %*% gamma_ME + epsilon
  return(Y_star)
  
}
```

I used the function to estimate the distribution of the fixed effects coefficient \textcolor{blue}{$\beta$}.  
Using Parametric Bootstrap sampling for $Y$, I then calculated OLS and ME (GLS) models. For the OLS model, the $COV(\beta_{OLS})$ is constant, since it's dependent the the known \textcolor{purple}{X} matrix alone. For the Mixed Effects model, $COV(\beta_{ME})$ is dependent on the variance of the random effect and the residuals. Therefore these were calculated for each iteration using the $lmer$ command (as instructed at the top of this assignment).

```{r Parametric Bootstrap sampling, warning = FALSE, message=FALSE}
B = 1000
bs_me   <- matrix(0, 3, B)
bs_ols  <- matrix(0, 7, B)
cov_beta_me <- matrix(0, 3, B)
cov_beta_ols <- solve(t(X_ols) %*% X_ols)
#cov_Y <- (sigma_random * Z %*% t(Z)) + (sigma_residual * diag(24))
for (i in 1:B){
  Y_star <- me_gen(X,Z,beta_ME, sigma_random,sigma_residual)
        ystar_data <- cbind(lawn_design[1:3], Y_star)
        me_ystar <- lmer(Y_star~manufact + speed + (1 | machine),data=ystar_data)
            star_sigma_random <- as.data.frame(VarCorr(me_ystar))$vcov[1]
            star_sigma_residual <- as.data.frame(VarCorr(me_ystar))$vcov[2]
            cov_Y <- (star_sigma_random * Z %*% t(Z)) + (star_sigma_residual * diag(24))
              bs_ols[,i]<- solve(t(X_ols) %*% X_ols) %*% (t(X_ols) %*% Y_star)
              cov_beta_me_loop <- solve(t(X) %*% solve(cov_Y) %*% X)
              bs_me[,i]<- (cov_beta_me_loop) %*% (t(X)%*% solve(cov_Y) %*%Y_star)
              cov_beta_me[,i] <- diag(cov_beta_me_loop)
}
dif_abs <- ifelse(sum(abs(bs_ols[1:3,]-bs_me))<0.0001,"smaller than 0.0001",ifelse(sum(abs(bs_ols[1:3,]-bs_me))<0.001,"smaller than 0.001", sum(abs(bs_ols[1:3]-bs_me))))
df_bs_me <- as.data.frame(t(bs_me))
colnames(df_bs_me) <- c("intercept", "manufacturer", "speed")
```


The estimates of \textcolor{blue}{$\beta$} are practicly identical. After `r B` iterations, the sum of the absolute difference ${\beta_{OLS} - \beta_{ME}}$ is `r dif_abs`.  
The distribution of the estimators is presented in the following histograms, with the original parameter added.

```{r Histograms estimations, fig.width=8, fig.height=9, fig.align='center'}
intercept_plot <- ggplot(df_bs_me, aes(x=intercept)) +
    geom_freqpoly(binwidth=2) +
    geom_vline(xintercept=beta_ME[1], color="blue", size=2)
manufacturer_plot <- ggplot(df_bs_me, aes(x=manufacturer)) +
    geom_freqpoly(binwidth=2) +
    geom_vline(xintercept=beta_ME[2], color="green", size=2)
speed_plot <- ggplot(df_bs_me, aes(x=speed)) +
    geom_freqpoly(binwidth=2) +
    geom_vline(xintercept=beta_ME[3], color="purple", size=2)

grid.arrange(intercept_plot, manufacturer_plot, speed_plot, nrow=3)
```
  
As for the estimates of $COV(\hat{\beta})$, there is a difference between the ME and OLS models. I calculated the RMSE of $Var(\hat{\beta})$ using the formula: 
$$ RMSE = \sqrt{\frac{\sum_{i=1}^{B} (Var(\hat{\beta})-Var(\beta_{ME}))}{B}}$$ 
With $Var(\beta_{ME})$ as the true parameter, since this was the model used for sampling and theoretically better represents the data. I added it to the table summarizing the RMSE to demonstrate the much larger variance calculated by the OLS model, relative to the original variance.

```{r RMSE}
rmse_me_detail <- (cov_beta_me - diag(cov_betaME))
rmse_me_detail <- apply(rmse_me_detail, c(1,2), function(x) x^2)
rmse_me <- apply(rmse_me_detail, 1, sum)
rmse_me <- sqrt(rmse_me/B)

# when calculating for OLS, the variance of the estimator is identical for all the iterations since it's dependent solely on X.
#Therefore, summing B times and dividing by B cancel out.
rmse_ols_detail <- (diag(cov_beta_ols[1:3, 1:3]) - diag(cov_betaME))^2
rmse_ols <- sqrt(rmse_ols_detail)


rmse_compare <- rbind(diag(cov_betaME), rmse_me, rmse_ols)
rownames(rmse_compare) <- c("Original variance of parametor","Mixed effects", "OLS")

kable(rmse_compare, format="latex", booktabs=T) %>%
  row_spec(1,color="blue")

```

The comparison of RMSE of both methods demonstrates that ME better estimates the parameter.  
  
## Conclusion  
  
to summarize the results of the analysis, I checked the significance of the $\hat\beta_{ME}$ by dividing the estimator with the standard deviation calculated. based on the following results I concluded that both manufacturers and speed are significant in predicting the time as a proxy of efficiency of the lawn mower.

```{r}
significance_t_value <- beta_ME / sqrt(diag(cov_betaME))
#p_value_beta <- pt(significance_t_value, B-1)
significance_table <- cbind(beta_ME, significance_t_value)

colnames(significance_table) <- cbind("Estimation", "t value")

kable(round(significance_table, 3), format="latex", booktabs=T)
```

I would further conclude that Generalized Least Square in the form of Mixed Effects model is the most appropriate model for this data.

